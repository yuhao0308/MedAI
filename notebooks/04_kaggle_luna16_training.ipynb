{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "LUNA16 Lung Nodule Segmentation Training Script\n",
        "Bug-free 3D medical image segmentation with MONAI and SwinUNETR\n",
        "\n",
        "This is a complete, copy-paste ready script for Kaggle.\n",
        "All shape mismatch issues have been fixed.\n",
        "\n",
        "USAGE ON KAGGLE:\n",
        "1. Upload LUNA16 preprocessed dataset as a Kaggle dataset\n",
        "2. Create new notebook and enable GPU accelerator\n",
        "3. Copy-paste this entire script into a code cell\n",
        "4. Update BIDS_ROOT path to match your dataset\n",
        "5. Run!\n",
        "\"\"\"\n",
        "\n",
        "# ============================================\n",
        "# SECTION 1: ENVIRONMENT SETUP\n",
        "# ============================================\n",
        "\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "from datetime import datetime\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
        "\n",
        "# PyTorch\n",
        "import torch.nn as nn\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "\n",
        "# MONAI\n",
        "from monai.losses import DiceCELoss\n",
        "from monai.metrics import DiceMetric\n",
        "from monai.networks.nets import SwinUNETR\n",
        "from monai.data import DataLoader, CacheDataset, Dataset, decollate_batch\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd, Spacingd,\n",
        "    Orientationd, ScaleIntensityRanged, RandCropByPosNegLabeld,\n",
        "    RandRotate90d, RandFlipd, ToTensord, Transform,\n",
        "    DivisiblePadd, AsDiscrete, CropForegroundd, RandGaussianNoised\n",
        ")\n",
        "from monai.inferers import sliding_window_inference\n",
        "\n",
        "# Scipy & Nibabel\n",
        "import nibabel as nib\n",
        "from scipy import ndimage\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "# ============================================\n",
        "# SECTION 2: CONFIGURATION\n",
        "# ============================================\n",
        "\n",
        "CONFIG = {\n",
        "    \"paths\": {\n",
        "        # üîß CHANGE THIS to match your Kaggle dataset path\n",
        "        \"bids_root\": \"/kaggle/input/luna16-processed/luna16_processed\",\n",
        "        \"output_dir\": \"/kaggle/working\",\n",
        "    },\n",
        "    \"selection\": {\n",
        "        \"subset_size\": 50,\n",
        "        \"target_positive_ratio\": 0.6,\n",
        "        \"random_seed\": 42,\n",
        "    },\n",
        "    \"model\": {\n",
        "        \"type\": \"SwinUNETR\",\n",
        "        \"in_channels\": 1,\n",
        "        \"out_channels\": 2,  # Background + Nodule\n",
        "        \"img_size\": [96, 96, 96],  # Model input size (must be divisible by 32)\n",
        "        \"feature_size\": 48,  # Reduce to 24 if OOM\n",
        "        \"use_checkpoint\": True,\n",
        "    },\n",
        "    \n",
        "    \"training\": {\n",
        "        \"spatial_size\": [96, 96, 96],  # Patch size (matches img_size)\n",
        "        \"batch_size\": 1,\n",
        "        \"num_epochs\": 80,\n",
        "        \"learning_rate\": 1e-4,\n",
        "        \"num_workers\": 2,\n",
        "        \"cache_rate\": 0.5,\n",
        "        \"val_interval\": 2,\n",
        "        \"randcrop\": {\n",
        "            \"pos\": 4,  # Increased from 3 - more positive samples\n",
        "            \"neg\": 1,\n",
        "            \"num_samples\": 4,\n",
        "        },\n",
        "    },\n",
        "    \n",
        "    \"preprocessing\": {\n",
        "        \"spacing\": [1.5, 1.5, 1.5],\n",
        "        \"orientation\": \"RAS\",\n",
        "        \"intensity_range\": [-1000.0, 400.0],  # Lung CT window\n",
        "        \"target_range\": [0.0, 1.0],\n",
        "        \"divisible_k\": 32,\n",
        "    },\n",
        "}\n",
        "\n",
        "OUTPUT_DIR = Path(CONFIG[\"paths\"][\"output_dir\"])\n",
        "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(OUTPUT_DIR / \"config.json\", \"w\") as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"CONFIGURATION\")\n",
        "print(\"=\"*70)\n",
        "print(json.dumps(CONFIG, indent=2))\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# ============================================\n",
        "# SECTION 3: DATA LOADING & STRATIFIED SPLIT\n",
        "# ============================================\n",
        "\n",
        "def read_luna16_dataset(bids_root: Path, verbose: bool = True) -> List[Dict[str, str]]:\n",
        "    \"\"\"\n",
        "    Read LUNA16 dataset in BIDS format with robust error handling.\n",
        "    \"\"\"\n",
        "    if verbose:\n",
        "        print(f\"\\nüìÇ Scanning BIDS dataset: {bids_root}\")\n",
        "    \n",
        "    bids_root = Path(bids_root)\n",
        "    \n",
        "    if not bids_root.exists():\n",
        "        raise ValueError(f\"‚ùå BIDS root does not exist: {bids_root}\")\n",
        "    \n",
        "    data_dicts = []\n",
        "    \n",
        "    # Find all subject directories\n",
        "    subject_dirs = sorted([d for d in bids_root.iterdir() \n",
        "                          if d.is_dir() and d.name.startswith(\"sub-\")])\n",
        "    \n",
        "    if len(subject_dirs) == 0:\n",
        "        raise ValueError(f\"‚ùå No subject directories found in {bids_root}\")\n",
        "    \n",
        "    if verbose:\n",
        "        print(f\"   Found {len(subject_dirs)} subjects\")\n",
        "    \n",
        "    for sub_dir in subject_dirs:\n",
        "        sub_id = sub_dir.name\n",
        "        try:\n",
        "            # Look for image and label files\n",
        "            img_candidates = list((sub_dir / \"anat\").glob(\"*CT*.nii*\")) + list((sub_dir / \"anat\").glob(\"*.nii*\"))\n",
        "            label_dir = bids_root / \"derivatives\" / \"labels\" / sub_id / \"anat\"\n",
        "            if not label_dir.exists():\n",
        "                continue\n",
        "            lbl_candidates = list(label_dir.glob(\"*seg*mask.nii*\")) + list(label_dir.glob(\"*.nii*\"))\n",
        "            \n",
        "            if img_candidates and lbl_candidates:\n",
        "                data_dicts.append({\n",
        "                    \"image\": str(img_candidates[0]),\n",
        "                    \"label\": str(lbl_candidates[0]),\n",
        "                    \"subject_id\": sub_id,\n",
        "                })\n",
        "        except Exception:\n",
        "            continue\n",
        "    \n",
        "    if len(data_dicts) == 0:\n",
        "        raise ValueError(\"‚ùå No valid image-label pairs found!\")\n",
        "    \n",
        "    return data_dicts\n",
        "\n",
        "def analyze_subject(data_dict):\n",
        "    \"\"\"Analyze if subject has nodules.\"\"\"\n",
        "    mask = nib.load(data_dict[\"label\"]).get_fdata()\n",
        "    has_nodules = np.any(mask > 0)\n",
        "    info = {\n",
        "        \"subject_id\": data_dict[\"subject_id\"],\n",
        "        \"has_nodules\": has_nodules,\n",
        "        \"data_dict\": data_dict,\n",
        "    }\n",
        "    return info\n",
        "\n",
        "def stratified_select_and_split(data_dicts):\n",
        "    \"\"\"Select balanced subset and split stratified.\"\"\"\n",
        "    print(\"   Analyzing subjects for stratification...\")\n",
        "    analyses = [analyze_subject(d) for d in data_dicts]\n",
        "    positive = [a for a in analyses if a[\"has_nodules\"]]\n",
        "    negative = [a for a in analyses if not a[\"has_nodules\"]]\n",
        "    \n",
        "    random.seed(CONFIG[\"selection\"][\"random_seed\"])\n",
        "    \n",
        "    # Select subset\n",
        "    n_total = CONFIG[\"selection\"][\"subset_size\"]\n",
        "    n_pos = min(int(n_total * CONFIG[\"selection\"][\"target_positive_ratio\"]), len(positive))\n",
        "    n_neg = min(n_total - n_pos, len(negative))\n",
        "    \n",
        "    selected = random.sample(positive, n_pos) + random.sample(negative, n_neg)\n",
        "    random.shuffle(selected)\n",
        "    \n",
        "    # Helper to split list\n",
        "    def split_list(items, train_ratio=0.7, val_ratio=0.15):\n",
        "        random.shuffle(items)\n",
        "        n = len(items)\n",
        "        n_train = int(n * train_ratio)\n",
        "        n_val = int(n * val_ratio)\n",
        "        return {\n",
        "            \"train\": [i[\"data_dict\"] for i in items[:n_train]],\n",
        "            \"val\": [i[\"data_dict\"] for i in items[n_train:n_train+n_val]],\n",
        "            \"test\": [i[\"data_dict\"] for i in items[n_train+n_val:]],\n",
        "        }\n",
        "\n",
        "    splits = {\"train\": [], \"val\": [], \"test\": []}\n",
        "    pos_splits = split_list([a for a in selected if a[\"has_nodules\"]])\n",
        "    neg_splits = split_list([a for a in selected if not a[\"has_nodules\"]])\n",
        "\n",
        "    for key in [\"train\", \"val\", \"test\"]:\n",
        "        splits[key] = pos_splits[key] + neg_splits[key]\n",
        "        random.shuffle(splits[key])\n",
        "        \n",
        "    summary = {\n",
        "        \"total\": len(selected),\n",
        "        \"train\": len(splits[\"train\"]),\n",
        "        \"val\": len(splits[\"val\"]),\n",
        "        \"test\": len(splits[\"test\"]),\n",
        "        \"train_pos\": sum(analyze_subject(d)[\"has_nodules\"] for d in splits[\"train\"]),\n",
        "        \"val_pos\": sum(analyze_subject(d)[\"has_nodules\"] for d in splits[\"val\"]),\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nüìä Selection & Split Summary:\")\n",
        "    print(f\"   Selected: {summary['total']} subjects\")\n",
        "    print(f\"   Train: {summary['train']} (Pos: {summary['train_pos']})\")\n",
        "    print(f\"   Val:   {summary['val']} (Pos: {summary['val_pos']})\")\n",
        "    print(f\"   Test:  {summary['test']}\")\n",
        "    \n",
        "    return splits\n",
        "\n",
        "# Load dataset\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(\"LOADING DATASET\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "try:\n",
        "    BIDS_ROOT = Path(CONFIG[\"paths\"][\"bids_root\"])\n",
        "    data_dicts = read_luna16_dataset(BIDS_ROOT, verbose=True)\n",
        "    splits = stratified_select_and_split(data_dicts)\n",
        "    \n",
        "    # Save split info\n",
        "    split_info = {k: [d[\"subject_id\"] for d in v] for k, v in splits.items()}\n",
        "    with open(OUTPUT_DIR / \"data_splits.json\", \"w\") as f:\n",
        "        json.dump(split_info, f, indent=2)\n",
        "    \n",
        "    print(\"=\"*70 + \"\\n\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå ERROR loading dataset: {e}\")\n",
        "    raise\n",
        "\n",
        "# ============================================\n",
        "# SECTION 4: TRANSFORMS\n",
        "# ============================================\n",
        "\n",
        "class BinarizeLabeld(Transform):\n",
        "    def __init__(self, keys):\n",
        "        self.keys = keys\n",
        "    def __call__(self, data):\n",
        "        for key in self.keys:\n",
        "            data[key] = (data[key] > 0).float()\n",
        "        return data\n",
        "\n",
        "def get_train_transforms(config):\n",
        "    return Compose([\n",
        "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=config[\"preprocessing\"][\"spacing\"], mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=config[\"preprocessing\"][\"orientation\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"],\n",
        "            a_min=config[\"preprocessing\"][\"intensity_range\"][0],\n",
        "            a_max=config[\"preprocessing\"][\"intensity_range\"][1],\n",
        "            b_min=config[\"preprocessing\"][\"target_range\"][0],\n",
        "            b_max=config[\"preprocessing\"][\"target_range\"][1],\n",
        "            clip=True,\n",
        "        ),\n",
        "        BinarizeLabeld(keys=[\"label\"]),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", margin=8, allow_smaller=True),\n",
        "        DivisiblePadd(keys=[\"image\", \"label\"], k=config[\"preprocessing\"][\"divisible_k\"]),\n",
        "        RandCropByPosNegLabeld(\n",
        "            keys=[\"image\", \"label\"],\n",
        "            label_key=\"label\",\n",
        "            spatial_size=config[\"training\"][\"spatial_size\"],\n",
        "            pos=config[\"training\"][\"randcrop\"][\"pos\"],\n",
        "            neg=config[\"training\"][\"randcrop\"][\"neg\"],\n",
        "            num_samples=config[\"training\"][\"randcrop\"][\"num_samples\"],\n",
        "            allow_smaller=True,\n",
        "        ),\n",
        "        RandGaussianNoised(keys=[\"image\"], prob=0.1, mean=0.0, std=0.01),\n",
        "        RandRotate90d(keys=[\"image\", \"label\"], prob=0.2, spatial_axes=(0, 1)),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.2, spatial_axis=0),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.2, spatial_axis=1),\n",
        "        RandFlipd(keys=[\"image\", \"label\"], prob=0.2, spatial_axis=2),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ])\n",
        "\n",
        "def get_val_transforms(config):\n",
        "    return Compose([\n",
        "        LoadImaged(keys=[\"image\", \"label\"], image_only=False),\n",
        "        EnsureChannelFirstd(keys=[\"image\", \"label\"]),\n",
        "        Spacingd(keys=[\"image\", \"label\"], pixdim=config[\"preprocessing\"][\"spacing\"], mode=(\"bilinear\", \"nearest\")),\n",
        "        Orientationd(keys=[\"image\", \"label\"], axcodes=config[\"preprocessing\"][\"orientation\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"],\n",
        "            a_min=config[\"preprocessing\"][\"intensity_range\"][0],\n",
        "            a_max=config[\"preprocessing\"][\"intensity_range\"][1],\n",
        "            b_min=config[\"preprocessing\"][\"target_range\"][0],\n",
        "            b_max=config[\"preprocessing\"][\"target_range\"][1],\n",
        "            clip=True,\n",
        "        ),\n",
        "        BinarizeLabeld(keys=[\"label\"]),\n",
        "        CropForegroundd(keys=[\"image\", \"label\"], source_key=\"image\", margin=8, allow_smaller=True),\n",
        "        DivisiblePadd(keys=[\"image\", \"label\"], k=config[\"preprocessing\"][\"divisible_k\"]),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ])\n",
        "\n",
        "print(\"‚úÖ Transform pipelines defined\\n\")\n",
        "\n",
        "# ============================================\n",
        "# SECTION 5: CREATE DATASETS AND DATALOADERS\n",
        "# ============================================\n",
        "\n",
        "train_transforms = get_train_transforms(CONFIG)\n",
        "val_transforms = get_val_transforms(CONFIG)\n",
        "\n",
        "train_dataset = CacheDataset(\n",
        "    data=splits[\"train\"],\n",
        "    transform=train_transforms,\n",
        "    cache_rate=CONFIG[\"training\"][\"cache_rate\"],\n",
        "    num_workers=CONFIG[\"training\"][\"num_workers\"],\n",
        ")\n",
        "val_dataset = CacheDataset(\n",
        "    data=splits[\"val\"],\n",
        "    transform=val_transforms,\n",
        "    cache_rate=CONFIG[\"training\"][\"cache_rate\"],\n",
        "    num_workers=CONFIG[\"training\"][\"num_workers\"],\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=CONFIG[\"training\"][\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=0,  # Use 0 for Kaggle\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=1,\n",
        "    shuffle=False,\n",
        "    num_workers=0,  # Use 0 for Kaggle\n",
        "    pin_memory=torch.cuda.is_available(),\n",
        ")\n",
        "\n",
        "print(f\"‚úÖ DataLoaders created (Train: {len(train_loader)}, Val: {len(val_loader)})\")\n",
        "\n",
        "# ============================================\n",
        "# SECTION 6: MODEL DEFINITION\n",
        "# ============================================\n",
        "\n",
        "print(\"=\"*70)\n",
        "print(\"CREATING MODEL\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "model = SwinUNETR(\n",
        "    img_size=CONFIG[\"model\"][\"img_size\"],\n",
        "    in_channels=CONFIG[\"model\"][\"in_channels\"],\n",
        "    out_channels=CONFIG[\"model\"][\"out_channels\"],\n",
        "    feature_size=CONFIG[\"model\"][\"feature_size\"],\n",
        "    use_checkpoint=CONFIG[\"model\"][\"use_checkpoint\"],\n",
        ").to(device)\n",
        "\n",
        "# Using DiceCELoss with class weights to handle severe class imbalance\n",
        "# Nodules are tiny compared to background, so we weight foreground heavily\n",
        "try:\n",
        "    ce_weights = torch.tensor([0.1, 0.9]).to(device)  # Heavy emphasis on foreground\n",
        "    loss_function = DiceCELoss(\n",
        "        to_onehot_y=True,\n",
        "        softmax=True,\n",
        "        lambda_dice=1.0,\n",
        "        lambda_ce=1.0,\n",
        "        ce_weight=ce_weights,\n",
        "    )\n",
        "    print(\"   Using weighted DiceCELoss (0.1:0.9 bg:fg)\")\n",
        "except TypeError:\n",
        "    # Fallback for older MONAI versions without ce_weight\n",
        "    loss_function = DiceCELoss(\n",
        "        to_onehot_y=True,\n",
        "        softmax=True,\n",
        "        lambda_dice=1.0,\n",
        "        lambda_ce=0.5,  # Reduce CE contribution to let Dice dominate\n",
        "    )\n",
        "    print(\"   Using DiceCELoss (no class weights - older MONAI)\")\n",
        "\n",
        "dice_metric = DiceMetric(include_background=False, reduction=\"mean\", get_not_nans=False)\n",
        "\n",
        "# Post-processing transform for predictions only\n",
        "# Labels will be handled manually since they're already binary masks\n",
        "post_pred = Compose([AsDiscrete(argmax=True, to_onehot=2)])\n",
        "\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=CONFIG[\"training\"][\"learning_rate\"],\n",
        "    weight_decay=1e-5,\n",
        ")\n",
        "\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=CONFIG[\"training\"][\"num_epochs\"],\n",
        ")\n",
        "\n",
        "scaler = GradScaler(enabled=(device.type == \"cuda\"))\n",
        "\n",
        "print(\"\\n‚úÖ Model, loss, optimizer ready\")\n",
        "print(\"=\"*70 + \"\\n\")\n",
        "\n",
        "# ============================================\n",
        "# SECTION 7: TRAINING LOOP\n",
        "# ============================================\n",
        "\n",
        "history = {\n",
        "    \"train_loss\": [],\n",
        "    \"val_loss\": [],\n",
        "    \"val_dice\": [],\n",
        "    \"learning_rate\": [],\n",
        "}\n",
        "\n",
        "best_dice = 0.0\n",
        "best_epoch = 0\n",
        "\n",
        "def train_epoch(model, loader, optimizer, loss_fn, device, scaler):\n",
        "    model.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for batch in loader:\n",
        "        step += 1\n",
        "        inputs, labels = batch[\"image\"].to(device), batch[\"label\"].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        with autocast(enabled=(device.type == \"cuda\")):\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        epoch_loss += loss.item()\n",
        "    return epoch_loss / max(step, 1)\n",
        "\n",
        "def validate_epoch(model, loader, loss_fn, device, epoch_num=0):\n",
        "    model.eval()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    dice_metric.reset()\n",
        "    \n",
        "    # Track debug info\n",
        "    total_pred_foreground = 0\n",
        "    total_label_foreground = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in loader:\n",
        "            step += 1\n",
        "            inputs = batch[\"image\"].to(device)\n",
        "            labels = batch[\"label\"].to(device)\n",
        "            \n",
        "            with autocast(enabled=(device.type == \"cuda\")):\n",
        "                outputs = sliding_window_inference(\n",
        "                    inputs, CONFIG[\"model\"][\"img_size\"], 4, model, overlap=0.5\n",
        "                )\n",
        "                loss = loss_fn(outputs, labels)\n",
        "            epoch_loss += loss.item()\n",
        "            \n",
        "            # Decollate batch into individual samples\n",
        "            outputs_list = decollate_batch(outputs)\n",
        "            labels_list = decollate_batch(labels)\n",
        "            \n",
        "            # Post-process predictions: argmax + one-hot\n",
        "            outputs_post = [post_pred(i) for i in outputs_list]\n",
        "            \n",
        "            # Post-process labels: manually convert binary mask to one-hot\n",
        "            # Labels are [1, H, W, D] with values 0.0/1.0, we need [2, H, W, D] one-hot\n",
        "            labels_post = []\n",
        "            for label in labels_list:\n",
        "                # label shape: [1, H, W, D] with float values 0.0 or 1.0\n",
        "                foreground = label  # [1, H, W, D] - this IS the foreground channel\n",
        "                background = 1.0 - label  # [1, H, W, D] - complement is background\n",
        "                one_hot_label = torch.cat([background, foreground], dim=0)  # [2, H, W, D]\n",
        "                labels_post.append(one_hot_label)\n",
        "            \n",
        "            # Track statistics for debugging\n",
        "            for pred, lbl in zip(outputs_post, labels_post):\n",
        "                total_pred_foreground += pred[1].sum().item()\n",
        "                total_label_foreground += lbl[1].sum().item()\n",
        "            \n",
        "            dice_metric(y_pred=outputs_post, y=labels_post)\n",
        "    \n",
        "    mean_dice = dice_metric.aggregate().item()\n",
        "    dice_metric.reset()\n",
        "    \n",
        "    # Print debug info every 10 epochs or first epoch\n",
        "    if epoch_num == 0 or (epoch_num + 1) % 10 == 0:\n",
        "        print(f\"   [DEBUG] Total pred foreground voxels: {total_pred_foreground:.0f}\")\n",
        "        print(f\"   [DEBUG] Total label foreground voxels: {total_label_foreground:.0f}\")\n",
        "    \n",
        "    return epoch_loss / max(step, 1), mean_dice\n",
        "\n",
        "print(\"Starting training...\")\n",
        "\n",
        "try:\n",
        "    for epoch in range(CONFIG[\"training\"][\"num_epochs\"]):\n",
        "        print(f\"Epoch {epoch+1}/{CONFIG['training']['num_epochs']}\")\n",
        "        \n",
        "        train_loss = train_epoch(model, train_loader, optimizer, loss_function, device, scaler)\n",
        "        history[\"train_loss\"].append(train_loss)\n",
        "        history[\"learning_rate\"].append(optimizer.param_groups[0][\"lr\"])\n",
        "        \n",
        "        print(f\"   Train Loss: {train_loss:.4f}\")\n",
        "        \n",
        "        if (epoch + 1) % CONFIG[\"training\"][\"val_interval\"] == 0:\n",
        "            val_loss, val_dice = validate_epoch(model, val_loader, loss_function, device, epoch_num=epoch)\n",
        "            history[\"val_loss\"].append(val_loss)\n",
        "            history[\"val_dice\"].append(val_dice)\n",
        "            \n",
        "            print(f\"   Val Loss:   {val_loss:.4f}\")\n",
        "            print(f\"   Val Dice:   {val_dice:.4f}\")\n",
        "            \n",
        "            if val_dice > best_dice:\n",
        "                best_dice = val_dice\n",
        "                best_epoch = epoch + 1\n",
        "                torch.save({\n",
        "                    \"epoch\": epoch + 1,\n",
        "                    \"model_state_dict\": model.state_dict(),\n",
        "                    \"dice_score\": best_dice,\n",
        "                    \"config\": CONFIG,\n",
        "                }, OUTPUT_DIR / \"best_model.pth\")\n",
        "                print(f\"   ‚úÖ New best model saved!\")\n",
        "        \n",
        "        scheduler.step()\n",
        "        \n",
        "        # Periodic checkpoint\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            torch.save({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"model_state_dict\": model.state_dict(),\n",
        "                \"history\": history,\n",
        "            }, OUTPUT_DIR / f\"checkpoint_epoch{epoch+1}.pth\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"\\n‚ùå Training failed: {e}\")\n",
        "    raise\n",
        "\n",
        "finally:\n",
        "    # Save final\n",
        "    torch.save({\n",
        "        \"model_state_dict\": model.state_dict(),\n",
        "        \"config\": CONFIG,\n",
        "    }, OUTPUT_DIR / \"final_model.pth\")\n",
        "    \n",
        "    with open(OUTPUT_DIR / \"training_history.json\", \"w\") as f:\n",
        "        json.dump(history, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\"*70)\n",
        "print(f\"TRAINING COMPLETE. Best Dice: {best_dice:.4f} at epoch {best_epoch}\")\n",
        "print(\"=\"*70 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
